{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T16:43:03.930142Z",
     "start_time": "2018-11-08T16:43:03.927079Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py35tensorflow/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "import edward as ed\n",
    "from edward.models import Beta\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T19:33:06.946406Z",
     "start_time": "2018-11-08T19:33:06.908605Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('kronecker-core-periphery-n1024-h10-r0_01-0_25-1000-cascades.txt','r') as f:\n",
    "    \n",
    "    # Store number of nodes\n",
    "    numNodes = -1\n",
    "    while True:\n",
    "        if f.readline() == \"\\n\":\n",
    "            break\n",
    "        numNodes+=1\n",
    "\n",
    "    # Collect cascades into list\n",
    "    v = []\n",
    "    for line in f.readlines():\n",
    "        v.append([float(l) for l in line.rstrip('\\n').split(\",\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T16:57:52.441863Z",
     "start_time": "2018-11-09T16:57:52.404861Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_cascades = np.zeros((len(v),numNodes))\n",
    "for row, cascade in enumerate(v):  \n",
    "    c_nodes = [int(cascade[i*2]) for i in range(len(cascade)//2)]\n",
    "    c_times = [cascade[i*2+1] for i in range(len(cascade)//2)]\n",
    "\n",
    "    for col in range(len(c_nodes)):\n",
    "        np_cascades[row][c_nodes[col]]=c_times[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T15:35:52.319672Z",
     "start_time": "2018-11-09T15:35:52.306575Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def infectedCascade(cascade, start,N, T=10):\n",
    "    A_inf = lil_matrix((cascade.shape[0],cascade.shape[0]))\n",
    "\n",
    "    infected = np.nonzero(cascade)[0]\n",
    "    c_nodes= cascade.argsort()[-len(infected):]\n",
    "\n",
    "    for i in range(len(c_nodes)):\n",
    "        for j in range(i):\n",
    "            if cascade[j] < T:\n",
    "                A_inf[(c_nodes[i],c_nodes[j])]=cascade[i]-cascade[j]\n",
    "    \n",
    "    return A_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T16:20:18.589438Z",
     "start_time": "2018-11-09T16:20:18.585070Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uninfectedCascade(cascade,start,N,T=10):\n",
    "    nodes = {s for s in range(N)}\n",
    "    A_uninf = lil_matrix((N,N))\n",
    "\n",
    "    infected = np.nonzero(cascade)[0]\n",
    "    c_nodes= cascade.argsort()[-len(infected):]\n",
    "\n",
    "    for i in range(len(c_nodes)):\n",
    "        for j in (nodes-set(c_nodes)):\n",
    "            A_uninf[c_nodes[i],j]=T-cascade[i]\n",
    "\n",
    "    return A_uninf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    try: \n",
    "        return 1 / (1 + math.exp(-x))\n",
    "    except OverflowError:\n",
    "        if x > 0: \n",
    "            return 1\n",
    "        else: \n",
    "            return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T17:03:53.927814Z",
     "start_time": "2018-11-09T17:03:53.923838Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numNodes = 5\n",
    "#np_cascades.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T17:03:51.118787Z",
     "start_time": "2018-11-09T17:03:51.069847Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = Beta(tf.ones([numNodes,numNodes]),tf.ones([numNodes,numNodes]))\n",
    "cascade_ph = Cascade(A)\n",
    "\n",
    "sess.run(cascade_ph._log_prob(np.array([0,1,1,0,0])))\n",
    "\n",
    "# dir(cascade_ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T16:37:28.031495Z",
     "start_time": "2018-11-09T16:37:28.027187Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_cascades.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T16:37:28.548729Z",
     "start_time": "2018-11-09T16:37:28.546340Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {cascade_ph: np_cascades[0]}\n",
    "inference = ed.MAP([A], data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T16:37:32.265726Z",
     "start_time": "2018-11-09T16:37:30.046854Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T16:37:39.423811Z",
     "start_time": "2018-11-09T16:37:37.206515Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = ed.get_session()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "inference.run(n_iter=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T16:53:17.371765Z",
     "start_time": "2018-11-09T16:53:17.356704Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "\n",
    "from edward.models.random_variable import RandomVariable\n",
    "from tensorflow.contrib.distributions import Distribution\n",
    "\n",
    "try:\n",
    "    from tensorflow.contrib.distributions import FULLY_REPARAMETERIZED\n",
    "except Exception as e:\n",
    "    raise ImportError(\"{0}. Your TensorFlow version is not supported.\".format(e))\n",
    "\n",
    "class Cascade(RandomVariable, Distribution):\n",
    "    def __init__(self,\n",
    "                params,\n",
    "                seed_set = None,\n",
    "                seed_set_param = 0.01,\n",
    "                validate_args=False,\n",
    "                allow_nan_stats=True,\n",
    "                name=\"Cascade\"):\n",
    "        \"\"\"Initialize a `Cascade` random variable.\n",
    "        Args:\n",
    "            params: tf.Tensor.\n",
    "            Collection of samples. Its outer (left-most) dimension\n",
    "            determines the number of samples.\n",
    "        \"\"\"\n",
    "        parameters = locals()\n",
    "        with tf.name_scope(name, values=[params]):\n",
    "            with tf.control_dependencies([]):\n",
    "                self._params = tf.identity(params, name=\"alpha\")\n",
    "                self._seed_set = seed_set\n",
    "                self._seed_set_param = seed_set_param\n",
    "                try:\n",
    "                    self._n = tf.shape(self._params)[0] \n",
    "                except ValueError:  # scalar params\n",
    "                    self._n = tf.constant(1)\n",
    "                    \n",
    "        super(Cascade, self).__init__(\n",
    "            dtype=self._params.dtype,\n",
    "            reparameterization_type=FULLY_REPARAMETERIZED,\n",
    "            validate_args=validate_args,\n",
    "            allow_nan_stats=allow_nan_stats,\n",
    "            parameters=parameters,\n",
    "            graph_parents=[self._params, self._n],\n",
    "            name=name)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _param_shapes(sample_shape):\n",
    "        return {\"params\": tf.convert_to_tensor(sample_shape, dtype=tf.int32)}\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        \"\"\"Distribution parameter.\"\"\"\n",
    "        return self._params\n",
    "\n",
    "    @property\n",
    "    def n(self):\n",
    "        \"\"\"Number of samples.\"\"\"\n",
    "        return self._n\n",
    "\n",
    "    def _batch_shape_tensor(self):\n",
    "        return array_ops.shape(self.params)\n",
    "\n",
    "    def _batch_shape(self):\n",
    "        return self.params.shape[1:]\n",
    "\n",
    "    def _event_shape_tensor(self):\n",
    "        return tf.shape(self.params)[1:]\n",
    "\n",
    "    def _event_shape(self):\n",
    "        return tensor_shape.scalar()\n",
    "\n",
    "\n",
    "    \n",
    "    def _log_prob(self, value):\n",
    "\n",
    "        #alpha_tensor = tf.convert_to_tensor(tf.cast(self.params,dtype=tf.float64),dtype=tf.float64)\n",
    "        alpha_tensor = tf.Variable(self.params, dtype=tf.float64)\n",
    "        \n",
    "        I = tf.convert_to_tensor(infectedCascade(value,0,N=alpha_tensor.shape[0]).todense(),dtype = tf.float64)\n",
    "        U = tf.convert_to_tensor(uninfectedCascade(value,0,N=alpha_tensor.shape[0]).todense(),dtype = tf.float64)\n",
    "\n",
    "\n",
    "        psi_1 = -tf.reduce_sum(tf.multiply(alpha_tensor,I))\n",
    "        psi_2 = -tf.reduce_sum(tf.multiply(tf.transpose(alpha_tensor),U))\n",
    "        \n",
    "        zero_pos = tf.add(tf.multiply(tf.sign(I),-1),tf.ones((self.params.shape[0],self.params.shape[0]),dtype=tf.float64))\n",
    "        psi_3 = tf.reduce_sum(tf.log(tf.add(zero_pos,tf.multiply(tf.transpose(alpha_tensor),tf.sign(I)))))\n",
    "\n",
    "        return psi_1 + psi_2 + psi_3\n",
    "\n",
    "    def _sample_n(self, n=1, seed=None):\n",
    "\n",
    "        # generate the cascades\n",
    "        #if self._seed_set: \n",
    "        #    seedset = self._seed_set\n",
    "        #else: \n",
    "        #    seedset = np.random.binomial(1, self._seed_set_param,size=[N,1])\n",
    "        \n",
    "        #I_t = tf.convert_to_tensor(seedset)\n",
    "        #I_t_1 = tf.zeros((N,1))\n",
    "        A = self.parameters['params']\n",
    "        N = A.shape[0]\n",
    "        \n",
    "        #seedset = np.random.randint(2, size=N)\n",
    "        seedset = np.random.binomial(1, 0.0067,size=[N,1])\n",
    "        data = np.zeros((n,N))\n",
    "        for s in range(n):\n",
    "            I_t = np.array(seedset).reshape(N,1)\n",
    "            I_t_1 = np.zeros((N,1))\n",
    "            #beta_tau = np.matmul(beta, tau)\n",
    "            i = 1\n",
    "            data1 = np.zeros((N,1))\n",
    "            while not(np.array_equal(I_t,I_t_1)): \n",
    "                I_new = I_t - I_t_1\n",
    "                data1 += I_new*i\n",
    "                I_uninf = np.ones((N,1)) - I_t \n",
    "                AI = np.matmul(A.T, I_new)\n",
    "                # calculate probability\n",
    "                p = AI\n",
    "                p = np.apply_along_axis(sigmoid,1, p).reshape(N,1) * I_uninf\n",
    "\n",
    "                # draw random vector\n",
    "                I_t_1 = I_t\n",
    "                I_t = I_t_1 + np.random.binomial(1, p)\n",
    "                i += 1\n",
    "            data[s] = data1.flatten()\n",
    "            \n",
    "        \n",
    "        return tf.convert_to_tensor(data.reshape((n,N)))\n",
    "        \"\"\"\n",
    "                \n",
    "\n",
    "        \n",
    "        input_tensor = self.params\n",
    "        if len(input_tensor.shape) == 0:\n",
    "            input_tensor = tf.expand_dims(input_tensor, 0)\n",
    "            multiples = tf.concat([tf.expand_dims(n, 0), [1] * len(self.event_shape)], 0)\n",
    "            return tf.tile(input_tensor, multiples)\n",
    "        else: \n",
    "            probs = tf.ones([self.n]) / tf.cast(self.n, dtype=tf.float32)\n",
    "            cat = tf.contrib.distributions.Categorical(probs)\n",
    "            indices = cat._sample_n(n, seed)\n",
    "            print(input_tensor.shape)\n",
    "            print(indices.shape)\n",
    "            tensor = tf.gather(input_tensor, indices)\n",
    "            print(tensor.shape)\n",
    "            return tensor\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Error converting shape to a TensorShape: int() argument must be a string, a bytes-like object or a number, not 'Tensor'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m//anaconda/envs/py35tensorflow/lib/python3.5/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mmake_shape\u001b[0;34m(v, arg_name)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mas_shape\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m    851\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;31m# Got a list of dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mas_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;31m# Got a list of dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mas_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mas_dimension\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m       if (not isinstance(value, compat.bytes_or_text_types) and\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'Tensor'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-287-ed9ac6e7141b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Cascades should be of size c x n; Initialize the variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# TO DO: make A only NxN not c x NxN !!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   1744\u001b[0m                        \"eager execution.\")\n\u001b[1;32m   1745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1746\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_placeholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36m_placeholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   3045\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3047\u001b[0;31m   \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3048\u001b[0m   \u001b[0m_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35tensorflow/lib/python3.5/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mmake_shape\u001b[0;34m(v, arg_name)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error converting %s to a TensorShape: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     raise ValueError(\"Error converting %s to a TensorShape: %s.\" % (arg_name,\n",
      "\u001b[0;31mTypeError\u001b[0m: Error converting shape to a TensorShape: int() argument must be a string, a bytes-like object or a number, not 'Tensor'."
     ]
    }
   ],
   "source": [
    "## Initialize the values \n",
    "# Cascades should be of size c x n; Initialize the variables\n",
    "# TO DO: make A only NxN not c x NxN !!!!\n",
    "C = tf.placeholder(tf.float32, [c,N])\n",
    "A = Gamma(concentration=tf.zeros((c,N,N)), rate=tf.ones((c,N,N)))\n",
    "\n",
    "I_inf = tf.expand_dims(tf.where(C>0, x=tf.ones((c,N)), y=tf.zeros((c,N))),1)\n",
    "I_uninf = 1 - tf.expand_dims(tf.where(C>0, x=tf.ones((c,N)), y=tf.zeros((c,N))),1)\n",
    "t_max = tf.expand_dims(tf.reduce_max(C,1),1)\n",
    "\n",
    "#calculate dist1\n",
    "t_dist1 = tf.expand_dims(tf.subtract(t_max,C),1)\n",
    "\n",
    "#calculate dist2\n",
    "k = tf.concat([-tf.ones((c,N,1)),tf.expand_dims(C,-1)], 2)\n",
    "k_T = tf.transpose(tf.concat([tf.expand_dims(C,-1),tf.ones((c,N,1))], 2),perm=[0,2,1])\n",
    "t_dist2 = tf.matmul(k,k_T)\n",
    "\n",
    "# calculate psi_1 \n",
    "\n",
    "psi_1 = tf.multiply(tf.multiply(A,I_inf), tf.transpose(I_uninf, perm=[0,2,1]))\n",
    "psi_1 = tf.multiply(psi_1,t_dist1)\n",
    "psi_1 = tf.reduce_sum(-psi_1)\n",
    "\n",
    "# calculate psi_2\n",
    "\n",
    "psi_2 = tf.multiply(tf.where(t_dist2 > 0, A, tf.zeros((c,N,N))),tf.transpose(I_inf, perm=[0,2,1]))\n",
    "psi_2 = tf.multiply(psi_2,t_dist2)\n",
    "psi_2 = tf.reduce_sum(-psi_2)\n",
    "\n",
    "# calculate psi_3\n",
    "\n",
    "psi_3 = tf.multiply(tf.where(t_dist2 > 0, A, tf.zeros((c,N,N))), I_inf)\n",
    "psi_3 = tf.transpose(tf.log(tf.reduce_sum(psi_3,axis=2,keepdims=True)), perm=[0,2,1])\n",
    "psi_3 = tf.where(tf.logical_not(tf.is_inf(psi_3)), psi_3 , tf.zeros((c,1,N)))\n",
    "psi_3 = tf.reduce_sum(-psi_3)\n",
    "\n",
    "# log(p)\n",
    "\n",
    "log_p = psi_1 + psi_2\n",
    "c_i = tf.exp(log_p)\n",
    "\n",
    "I_uninf = tf.ones((c,N)) - I_inf\n",
    "\n",
    "# define log(p(c,A)) for a single cascade\n",
    "data={C: [[0,0,1,2,3],[0,1,0,2,3]]}\n",
    "sess = tf.Session()\n",
    "sess.run(log_p, feed_dict=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T16:53:17.919273Z",
     "start_time": "2018-11-09T16:53:17.860532Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha_test = np.random.uniform(0,1,[5,5])\n",
    "# print(v[0])\n",
    "x = Cascade(alpha_test)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(x.sample(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "D = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, [N, D])\n",
    "w = Normal(loc=tf.zeros(D), scale=tf.ones(D))\n",
    "b = Normal(loc=tf.zeros(1), scale=tf.ones(1))\n",
    "y = Normal(loc=ed.dot(X, w) + b, scale=tf.ones(N))\n",
    "\n",
    "qw = Normal(loc=tf.Variable,\n",
    "            scale=tf.nn.softplus(tf.get_variable(\"qw/scale3\", [D])))\n",
    "qb = Normal(loc=tf.get_variable(\"qb/loc3\", [1]),\n",
    "            scale=tf.nn.softplus(tf.get_variable(\"qb/scale3\", [1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.random.binomial(1, 0.01,size=[N,D])\n",
    "y_train = np.random.binomial(1, 0.01,size=[N])\n",
    "\n",
    "inference = ed.KLqp({w: qw, b: qb}, data={X: X_train, y: y_train})\n",
    "inference.run(n_samples=5, n_iter=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Aq = tf.Variable(tf.float32, [numNodes, numNodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from edward.models import PointMass\n",
    "A = Beta(tf.ones([numNodes,numNodes]),tf.ones([numNodes,numNodes]))\n",
    "cascade = Cascade(params=A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qA = PointMass(params= tf.get_variable(\"qA2\", [numNodes,numNodes], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qA = tf.get_variable(\"qA1\", [numNodes,numNodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simulate data \n",
    "X_train = np.random.binomial(1, 0.01,size=[N,numNodes])\n",
    "\n",
    "#model\n",
    "prior = Beta(tf.ones([numNodes,numNodes]),tf.ones([numNodes,numNodes]))\n",
    "cascade=Cascade(params=prior)\n",
    "\n",
    "#run inference\n",
    "A = ed.models.PointMass(params=tf.Variable(tf.zeros([numNodes, numNodes])))\n",
    "inference = ed.MAP({cascade: A}, data={X: X_train[0]})\n",
    "inference.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numNodes = 5\n",
    "data = np.random.binomial(1, 0.01,size=[100,numNodes])\n",
    "A = ed.models.PointMass(params=tf.Variable(tf.zeros([numNodes,numNodes])))\n",
    "\n",
    "inference = ed.MAP({params: A}, data = {cascade: data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = np.array([[1,2],[1,1]])\n",
    "s2 = np.array([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T16:13:53.046893Z",
     "start_time": "2018-11-09T16:13:52.966391Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha_test = np.ones((3,3),dtype=np.float64)/2\n",
    "\n",
    "testcascade = Cascade(alpha_test)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "test_list = [1., 0., 0., 1.5]\n",
    "sess.run(testcascade._log_prob(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T22:46:54.327110Z",
     "start_time": "2018-11-06T22:46:51.504112Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(cascade_ph._log_prob(v[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T23:47:44.763864Z",
     "start_time": "2018-11-08T23:47:44.644008Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from edward.models import Dirichlet, Beta, Multinomial, Bernoulli\n",
    "K=100\n",
    "N=50\n",
    "\n",
    "gamma = Dirichlet(concentration=tf.ones([K]))\n",
    "Pi = Beta(concentration0=tf.ones([K, K]), concentration1=tf.ones([K, K]))\n",
    "Z = Multinomial(total_count=1.0, probs=gamma, sample_shape=N)\n",
    "X = Bernoulli(probs=tf.matmul(Z, tf.matmul(Pi, tf.transpose(Z))))\n",
    "\n",
    "gamma.event_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = ed.models.Normal(loc=(0.0,1.0,6.0), scale=(.01,.01,.01))\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x._log_prob(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha_test = np.random.uniform(0,1,[5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = Cascade(alpha_test, seed_set=np.array([[1,0,0,1,0],[1,0,0,0,0]]))\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(c._n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a custom variable with shape (4 Gamma distributions who are independent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP using BFGS \n",
    "\n",
    "### Implement the model in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simulate dataset\n",
    "X_train = np.random.binomial(1, 0.01,size=[N,numNodes])\n",
    "\n",
    "value = X_train[0].astype(np.float64)\n",
    "\n",
    "numNodes = 5\n",
    "alpha_tensor = tf.Variable(tf.zeros([numNodes,numNodes],dtype=tf.float64), dtype=tf.float64)\n",
    "value = tf.placeholder(tf.float64, [numNodes, 1])    \n",
    "I = tf.convert_to_tensor(infectedCascade(value,0,N=alpha_tensor.shape[0]).todense(),dtype = tf.float64)\n",
    "U = tf.convert_to_tensor(uninfectedCascade(value,0,N=alpha_tensor.shape[0]).todense(),dtype = tf.float64)\n",
    "\n",
    "\n",
    "psi_1 = -tf.reduce_sum(tf.multiply(alpha_tensor,I))\n",
    "psi_2 = -tf.reduce_sum(tf.multiply(tf.transpose(alpha_tensor),U))\n",
    "        \n",
    "zero_pos = tf.add(tf.multiply(tf.sign(I),-1),tf.ones((numNodes,numNodes),dtype=tf.float64))\n",
    "psi_3 = tf.reduce_sum(tf.log(tf.add(zero_pos,tf.multiply(tf.transpose(alpha_tensor),tf.sign(I)))))\n",
    "\n",
    "log_prob = psi_1 + psi_2 + psi_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Initialize the values \n",
    "\n",
    "\n",
    "# Cascades should be of size c x n; Initialize the variables\n",
    "\n",
    "C = tf.placeholder(tf.float32, [c,N])\n",
    "\n",
    "B = tf.Variable(tf.random_normal([N,N]), dtype=tf.float32)\n",
    "\n",
    "A = tf.nn.softmax(B)\n",
    "#A = tf.Variable(tf.ones([N,N], dtype=tf.float32), dtype=tf.float32)\n",
    "\n",
    "\n",
    "I_inf = tf.expand_dims(tf.where(C>0, x=tf.ones((c,N)), y=tf.zeros((c,N))),1)\n",
    "I_uninf = 1 - tf.expand_dims(tf.where(C>0, x=tf.ones((c,N)), y=tf.zeros((c,N))),1)\n",
    "t_max = tf.expand_dims(tf.reduce_max(C,1),1)\n",
    "\n",
    "#calculate dist1\n",
    "t_mi = tf.expand_dims(tf.subtract(t_max,C),1)\n",
    "\n",
    "#calculate dist2\n",
    "k = tf.concat([-tf.ones((c,N,1)),tf.expand_dims(C,-1)], 2)\n",
    "k_T = tf.transpose(tf.concat([tf.expand_dims(C,-1),tf.ones((c,N,1))], 2),perm=[0,2,1])\n",
    "t_ij = tf.transpose(tf.matmul(k,k_T),perm=[0,2,1])\n",
    "\n",
    "# calculate psi_1 \n",
    "\n",
    "# fix time here!!!!\n",
    "psi_1 = tf.multiply(tf.multiply(A,I_inf), tf.transpose(I_uninf, perm=[0,2,1]))\n",
    "psi_1 = tf.reduce_sum(-tf.multiply(psi_1,t_mi))\n",
    "\n",
    "#psi_1 = tf.reduce_sum(tf.where(tf.is_inf(psi_1), tf.zeros_like(psi_1), psi_1))\n",
    "\n",
    "\n",
    "# calculate psi_2\n",
    "\n",
    "psi_2 = tf.multiply(tf.multiply(A,I_inf), tf.transpose(I_inf, perm=[0,2,1]))\n",
    "psi_2 = -tf.multiply(psi_2,t_ij)\n",
    "psi_2 = tf.reduce_sum(tf.where(t_ij > 0, psi_2,tf.zeros((c,N,N))))\n",
    "\n",
    "\n",
    "\n",
    "# calculate psi_3\n",
    "\n",
    "psi_3 = tf.multiply(tf.multiply(A,I_inf), tf.transpose(I_inf, perm=[0,2,1]))\n",
    "psi_3 = tf.reduce_sum(tf.where(t_ij > 0, psi_3,tf.zeros((c,N,N))), axis=1)\n",
    "psi_3 = tf.reduce_sum(tf.where(tf.is_inf(psi_3), tf.zeros_like(psi_3), psi_3))\n",
    "\n",
    "#psi_3 = tf.multiply(tf.where(t_dist2 > 0, tf.reshape(tf.tile(A,(c,1)),[c,N,N]), tf.zeros((c,N,N))), I_inf)\n",
    "#psi_3 = tf.transpose(tf.reduce_sum(psi_3,axis=2,keepdims=True), perm=[0,2,1])\n",
    "#psi_3 = tf.where(tf.logical_not(tf.is_inf(psi_3)), psi_3 , tf.zeros((c,1,N)))\n",
    "#psi_3 = tf.reduce_sum(-psi_3)\n",
    "\n",
    "# log(p)\n",
    "\n",
    "log_p = -(psi_1 + psi_2 + psi_3)\n",
    "#c_i = tf.exp(log_p)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 0.000008\n",
      "  Number of iterations: 15\n",
      "  Number of functions evaluations: 17\n",
      "[[ 7.6229234  -7.078423    0.7005998 ]\n",
      " [ 0.42220014 -1.4814656   1.120647  ]\n",
      " [-0.24601772  1.1918441   1.2852278 ]]\n",
      "[[9.9901509e-01 4.1196321e-07 9.8456652e-04]\n",
      " [3.1649086e-01 4.7163896e-02 6.3634521e-01]\n",
      " [1.0167136e-01 4.2820728e-01 4.7012144e-01]]\n"
     ]
    }
   ],
   "source": [
    "d = np.array([[0,1,2],\n",
    "            [0,1,2],\n",
    "           [0,1,2],\n",
    "           [0,1,2],\n",
    "           [0,1,2],\n",
    "           [0,1,2],\n",
    "           [0,1,2],\n",
    "             [0,1,2],\n",
    "           [0,1,2],\n",
    "           [0,1,2],\n",
    "           [0,1,2],\n",
    "           [0,1,2],\n",
    "             [0,1,2],\n",
    "           [0,1,2],\n",
    "           [0,1,2],\n",
    "           [0,1,2],\n",
    "           [0,1,2]])\n",
    "\n",
    "data = {C: d}\n",
    "c = d.shape[0]\n",
    "N = d.shape[1]\n",
    "max_iter = 1000\n",
    "\n",
    "optimizer = tf.contrib.opt.ScipyOptimizerInterface(log_p,\n",
    "                                                   method='L-BFGS-B',\n",
    "                                                   options={\n",
    "                                                    'maxiter': max_iter})\n",
    "model = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "with sess:\n",
    "    sess.run(model)\n",
    "    optimizer.minimize(sess, feed_dict=data)\n",
    "    print(B.eval(session=sess))\n",
    "    print(A.eval(session=sess))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape(None)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35tensorflow]",
   "language": "python",
   "name": "conda-env-py35tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
