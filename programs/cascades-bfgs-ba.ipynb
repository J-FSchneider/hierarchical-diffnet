{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Using-BFGS-to-obtain-MAP-estimate\" data-toc-modified-id=\"Using-BFGS-to-obtain-MAP-estimate-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Using BFGS to obtain MAP estimate</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-Functions\" data-toc-modified-id=\"Define-Functions-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Define Functions</a></span></li><li><span><a href=\"#Generate-Data\" data-toc-modified-id=\"Generate-Data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Generate Data</a></span></li></ul></li><li><span><a href=\"#Run-BFGS-on-Koenecker-Data\" data-toc-modified-id=\"Run-BFGS-on-Koenecker-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Run BFGS on Koenecker Data</a></span></li><li><span><a href=\"#Criticize-Results\" data-toc-modified-id=\"Criticize-Results-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Criticize Results</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BFGS to obtain MAP estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T17:07:24.138800Z",
     "start_time": "2018-11-26T17:07:24.134756Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import edward2 as ed\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:51:06.228086Z",
     "start_time": "2018-11-26T15:51:06.224176Z"
    }
   },
   "outputs": [],
   "source": [
    "# sess = ed.get_session()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:51:07.493130Z",
     "start_time": "2018-11-26T15:51:07.454081Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('kronecker-core-periphery-n1024-h10-r0_01-0_25-1000-cascades.txt','r') as f:\n",
    "    \n",
    "    # Store number of nodes\n",
    "    numNodes = -1\n",
    "    while True:\n",
    "        if f.readline() == \"\\n\":\n",
    "            break\n",
    "        numNodes+=1\n",
    "\n",
    "    # Collect cascades into list\n",
    "    v = []\n",
    "    for line in f.readlines():\n",
    "        v.append([float(l) for l in line.rstrip('\\n').split(\",\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:51:08.032782Z",
     "start_time": "2018-11-26T15:51:07.997724Z"
    }
   },
   "outputs": [],
   "source": [
    "np_cascades = np.ones((len(v),numNodes),np.float32)*10\n",
    "for row, cascade in enumerate(v):  \n",
    "    c_nodes = [int(cascade[i*2]) for i in range(len(cascade)//2)]\n",
    "    c_times = [cascade[i*2+1] for i in range(len(cascade)//2)]\n",
    "\n",
    "    for col in range(len(c_nodes)):\n",
    "        np_cascades[row][c_nodes[col]]=c_times[col]\n",
    "        \n",
    "casc = np_cascades[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:51:08.627742Z",
     "start_time": "2018-11-26T15:51:08.621179Z"
    }
   },
   "outputs": [],
   "source": [
    "def cascadeLogProb(time, seed):\n",
    "    np.where()\n",
    "    \n",
    "    \n",
    "    # Store number of nodes\n",
    "    n = time.shape[0]\n",
    "\n",
    "    # Transpose times and reduce minimum\n",
    "    times_T = tf.minimum(tf.transpose(time),T)\n",
    "\n",
    "    # Initialize transmission times to be max time except for seed node\n",
    "    transmission = tf.ones(n)*T\n",
    "    transmission = tf.subtract(transmission,tf.one_hot(seed, n)*T)\n",
    "\n",
    "    \n",
    "    # Continually update transmissions\n",
    "    for _ in range(n):\n",
    "\n",
    "        # Tile transmission\n",
    "        transmission_tiled = tf.reshape(tf.tile(transmission,[n]),[n,n])\n",
    "\n",
    "        # Add transposed times and tiled transmissions\n",
    "        potential_transmission = tf.add(transmission_tiled,times_T)\n",
    "\n",
    "        # Find minimum path from all new \n",
    "        potential_transmission_row = tf.reduce_min(potential_transmission, reduction_indices=[1])\n",
    "\n",
    "        # Concatenate previous transmission and potential new transmission\n",
    "        potential_transmission_stack = tf.stack([transmission,potential_transmission_row],axis=0)\n",
    "\n",
    "        # Take the minimum of the original transmission and the potential new transmission\n",
    "        transmission = tf.reduce_min(potential_transmission_stack, reduction_indices=[0])\n",
    "\n",
    "    return transmission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:51:09.724592Z",
     "start_time": "2018-11-26T15:51:09.717987Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_cascade(time, seed, T):\n",
    "    # Store number of nodes\n",
    "    n = time.shape[0]\n",
    "\n",
    "    # Transpose times and reduce minimum\n",
    "    times_T = tf.minimum(tf.transpose(time),T)\n",
    "\n",
    "    # Initialize transmission times to be max time except for seed node\n",
    "    transmission = tf.ones(n)*T\n",
    "    transmission = tf.subtract(transmission,tf.one_hot(seed, n)*T)\n",
    "\n",
    "    \n",
    "    # Continually update transmissions\n",
    "    for _ in range(n):\n",
    "\n",
    "        # Tile transmission\n",
    "        transmission_tiled = tf.reshape(tf.tile(transmission,[n]),[n,n])\n",
    "\n",
    "        # Add transposed times and tiled transmissions\n",
    "        potential_transmission = tf.add(transmission_tiled,times_T)\n",
    "\n",
    "        # Find minimum path from all new \n",
    "        potential_transmission_row = tf.reduce_min(potential_transmission, reduction_indices=[1])\n",
    "\n",
    "        # Concatenate previous transmission and potential new transmission\n",
    "        potential_transmission_stack = tf.stack([transmission,potential_transmission_row],axis=0)\n",
    "\n",
    "        # Take the minimum of the original transmission and the potential new transmission\n",
    "        transmission = tf.reduce_min(potential_transmission_stack, reduction_indices=[0])\n",
    "\n",
    "    return transmission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:51:12.914370Z",
     "start_time": "2018-11-26T15:51:12.689852Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha = np.array([[0, 1, 0, 0, .5, 0, 0, 0, 0, 0],\n",
    "                  [0, 0, 1, .3, 0, 0, 2, .5, 0, 0],\n",
    "                  [0, 0, 0, 1, 0, 0, 0, .2, 0, 0],\n",
    "                  [0, 0, 0, 0, 1, 0, .1, 0, .5, 0],\n",
    "                  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 1, 0, .2, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=np.float32)\n",
    "\n",
    "alpha_tf = tf.convert_to_tensor(alpha, dtype=tf.float32)\n",
    "\n",
    "tau = ed.Exponential(alpha)\n",
    "\n",
    "test_cascade = sess.run(build_cascade(tau, 0, 10))\n",
    "order = test_cascade.argsort()\n",
    "times = test_cascade[order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:51:24.031408Z",
     "start_time": "2018-11-26T15:51:24.024731Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def sampleCascade(alpha, T, n):\n",
    "    alpha_tf = tf.convert_to_tensor(alpha, dtype=tf.float32)\n",
    "    nodes = alpha.shape[0]\n",
    "    \n",
    "    cascade=[]\n",
    "    for i in tqdm_notebook(range(n)):\n",
    "        tau = ed.Exponential(alpha_tf)\n",
    "        seed = random.randint(0,nodes-1)\n",
    "        \n",
    "        tmpCascade = sess.run(build_cascade(tau, seed, T))\n",
    "        \n",
    "        order = tmpCascade.argsort()\n",
    "        times = tmpCascade[order]\n",
    "        \n",
    "        cascadeList=[]\n",
    "        \n",
    "        for i in range(nodes):\n",
    "            if times[i]>=T: break\n",
    "            cascadeList.append(float(order[i]))\n",
    "            cascadeList.append(times[i])\n",
    "            \n",
    "        cascade.append(cascadeList)    \n",
    "        \n",
    "    return cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:52:48.177692Z",
     "start_time": "2018-11-26T15:51:24.529051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f715b3d27a3b4c22975ac31d72006eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_cascade = sampleCascade(alpha,10,200)\n",
    "# test_cascade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run BFGS on Koenecker Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:52:48.736644Z",
     "start_time": "2018-11-26T15:52:48.733769Z"
    }
   },
   "outputs": [],
   "source": [
    "numNodes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:52:49.282898Z",
     "start_time": "2018-11-26T15:52:49.276600Z"
    }
   },
   "outputs": [],
   "source": [
    "def infectedCascade(cascade, N=numNodes, T=10):\n",
    "    inf = np.zeros((N,N))\n",
    "    \n",
    "    c_nodes = [int(cascade[i*2]) for i in range(len(cascade)//2)]\n",
    "    c_times = [cascade[i*2+1] for i in range(len(cascade)//2)]\n",
    "\n",
    "\n",
    "    for i in range(len(c_nodes)):\n",
    "        for j in range(i):\n",
    "            if cascade[j] < T:\n",
    "                inf[(c_nodes[i],c_nodes[j])]=c_times[i]-c_times[j]\n",
    "    \n",
    "    return tf.convert_to_tensor(inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:52:49.737978Z",
     "start_time": "2018-11-26T15:52:49.731978Z"
    }
   },
   "outputs": [],
   "source": [
    "def uninfectedCascade(cascade,N=numNodes,T=10):\n",
    "    nodes = {s for s in range(N)}\n",
    "    uninf = np.zeros((N,N))\n",
    "\n",
    "    c_nodes = [int(cascade[i*2]) for i in range(len(cascade)//2)]\n",
    "    c_times = [cascade[i*2+1] for i in range(len(cascade)//2)]\n",
    "\n",
    "    \n",
    "    for i in range(len(c_nodes)):\n",
    "        for j in (nodes-set(c_nodes)):\n",
    "            uninf[c_nodes[i],j]=T-c_times[i]\n",
    "\n",
    "    return tf.convert_to_tensor(uninf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:52:50.177365Z",
     "start_time": "2018-11-26T15:52:50.173197Z"
    }
   },
   "outputs": [],
   "source": [
    "def genInfectedTensor(v):\n",
    "    tf_infected = None\n",
    "    for cascade in v:\n",
    "        if tf_infected == None:\n",
    "            tf_infected = tf.expand_dims(infectedCascade(cascade),0)\n",
    "        else:\n",
    "            tf_infected = tf.concat([tf_infected,tf.expand_dims(infectedCascade(cascade),0)],axis=0)\n",
    "    return tf_infected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:52:50.655651Z",
     "start_time": "2018-11-26T15:52:50.651506Z"
    }
   },
   "outputs": [],
   "source": [
    "def genUninfectedTensor(v):\n",
    "    tf_uninfected = None\n",
    "    for cascade in v:\n",
    "        if tf_uninfected == None:\n",
    "            tf_uninfected = tf.expand_dims(uninfectedCascade(cascade),0)\n",
    "        else:\n",
    "            tf_uninfected = tf.concat([tf_uninfected,tf.expand_dims(uninfectedCascade(cascade),0)],axis=0)\n",
    "    return tf_uninfected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:52:52.204089Z",
     "start_time": "2018-11-26T15:52:51.677140Z"
    }
   },
   "outputs": [],
   "source": [
    "I = genInfectedTensor(test_cascade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:52:53.122077Z",
     "start_time": "2018-11-26T15:52:52.611086Z"
    }
   },
   "outputs": [],
   "source": [
    "U = genUninfectedTensor(test_cascade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T15:52:53.524103Z",
     "start_time": "2018-11-26T15:52:53.519199Z"
    }
   },
   "outputs": [],
   "source": [
    "U_ph = tf.placeholder(tf.float32, U.shape)\n",
    "I_ph = tf.placeholder(tf.float32, I.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:02:36.152541Z",
     "start_time": "2018-11-26T16:02:36.146549Z"
    }
   },
   "outputs": [],
   "source": [
    "# B = tf.Variable(tf.random_uniform(U.shape[1:], initializer=tf.ones_initializer), dtype=tf.float32)\n",
    "# B = tf.get_variable('alpha_input', initializer=tf.zeros_initializer, shape=U.shape[1:])\n",
    "alpha_tensor = tf.nn.relu(tf.add(B,.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:02:36.451400Z",
     "start_time": "2018-11-26T16:02:36.386464Z"
    }
   },
   "outputs": [],
   "source": [
    "def f_psi_1(alpha_tensor, infected):\n",
    "    return -tf.reduce_sum(tf.multiply(alpha_tensor,tf.cast(infected,dtype=tf.float32)))\n",
    "\n",
    "psi_1 = tf.map_fn(lambda x: f_psi_1(tf.transpose(alpha_tensor), x), I_ph, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:02:36.791337Z",
     "start_time": "2018-11-26T16:02:36.721409Z"
    }
   },
   "outputs": [],
   "source": [
    "def f_psi_2(alpha_tensor, uninfected):\n",
    "    return -tf.reduce_sum(tf.multiply(tf.transpose(alpha_tensor),tf.cast(uninfected,dtype=tf.float32)))\n",
    "\n",
    "psi_2 = tf.map_fn(lambda x: f_psi_2(tf.transpose(alpha_tensor), x), U_ph, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T16:02:37.211613Z",
     "start_time": "2018-11-26T16:02:37.140826Z"
    }
   },
   "outputs": [],
   "source": [
    "def f_psi_3(alpha_tensor, infected):\n",
    "    infected_sign = tf.cast(tf.sign(infected),tf.float32)\n",
    "    \n",
    "    # Row sum infected\n",
    "    alpha_tensor_row = tf.reduce_sum(tf.multiply(infected_sign,alpha_tensor),axis=1)\n",
    "    \n",
    "    # Add 1 to 0 entries so log(1)=0\n",
    "    alpha_tensor_row_zeros = -tf.cast(tf.sign(alpha_tensor_row),tf.float32)+1\n",
    "    \n",
    "    return tf.reduce_sum(tf.log(tf.add(alpha_tensor_row,alpha_tensor_row_zeros)))\n",
    "\n",
    "psi_3 = tf.map_fn(lambda x: f_psi_3(tf.transpose(alpha_tensor), x), I_ph, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T17:05:23.560605Z",
     "start_time": "2018-11-26T17:05:23.554639Z"
    }
   },
   "outputs": [],
   "source": [
    "def gamma_prior(alpha_tensor, beta_tensor):\n",
    "    return tf.multiply(-alpha_tensor,alpha_tensor)\n",
    "\n",
    "prior = gamma_prior(alpha_tensor,tf.ones(alpha_tensor.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T17:05:24.236625Z",
     "start_time": "2018-11-26T17:05:24.222764Z"
    }
   },
   "outputs": [],
   "source": [
    "log_p = -(tf.reduce_sum(prior) + tf.reduce_sum(psi_1)+tf.reduce_sum(psi_2)+tf.reduce_sum(psi_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity_tensor = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T17:05:30.471121Z",
     "start_time": "2018-11-26T17:05:24.770760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 967.430298\n",
      "  Number of iterations: 32\n",
      "  Number of functions evaluations: 46\n"
     ]
    }
   ],
   "source": [
    "max_iter = 2000\n",
    "\n",
    "data = {U_ph: U.eval(session=sess),\n",
    "        I_ph: I.eval(session=sess)}\n",
    "\n",
    "optimizer = tf.contrib.opt.ScipyOptimizerInterface(log_p, \n",
    "                                                   method='L-BFGS-B',\n",
    "                                                   options={'maxiter': max_iter})\n",
    "model = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(model)\n",
    "optimizer.minimize(sess, feed_dict=data)\n",
    "a = alpha_tensor.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T17:05:30.479898Z",
     "start_time": "2018-11-26T17:05:30.473526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.8, 0. , 0. , 0.5, 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 1.3, 0.2, 0. , 0. , 1.3, 0.4, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0.9, 0. , 0. , 0. , 0.2, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0.8, 0. , 0.1, 0. , 0.5, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0.9, 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 1.2, 0. , 0.2, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.9],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]], dtype=float32)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T17:05:30.493940Z",
     "start_time": "2018-11-26T17:05:30.483440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 1. , 0. , 0. , 0.5, 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 1. , 0.3, 0. , 0. , 2. , 0.5, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 1. , 0. , 0. , 0. , 0.2, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 1. , 0. , 0.1, 0. , 0.5, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 1. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 1. , 0. , 0.2, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]], dtype=float32)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criticize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T16:17:53.264109Z",
     "start_time": "2018-11-25T16:17:53.258723Z"
    }
   },
   "outputs": [],
   "source": [
    "def printCascade(cascade):\n",
    "    print(\"order\\t node\\t time\")\n",
    "    print(\"-----\\t ----\\t ----\")\n",
    "    for i in range(len(cascade)//2):\n",
    "        print('{:5d}\\t {:4d}\\t {:0.2f}'.format(i+1,int(cascade[i*2]), cascade[i*2+1]))\n",
    "\n",
    "printCascade(v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T16:23:44.236851Z",
     "start_time": "2018-11-25T16:23:44.234297Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T21:30:53.667894Z",
     "start_time": "2018-11-23T21:30:49.476Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer._var_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T21:30:53.668966Z",
     "start_time": "2018-11-23T21:30:49.478Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha = sess.run(optimizer._vars)[0]\n",
    "beta = sess.run(optimizer._vars)[1]\n",
    "tf.nn.relu(beta[753][261])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T21:30:53.669663Z",
     "start_time": "2018-11-23T21:30:49.480Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import tensorflow_probability\n",
    "# \n",
    "# .Beta(alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
