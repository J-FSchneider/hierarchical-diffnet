{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Using-BFGS-to-obtain-MAP-estimate\" data-toc-modified-id=\"Using-BFGS-to-obtain-MAP-estimate-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Using BFGS to obtain MAP estimate</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-Functions\" data-toc-modified-id=\"Define-Functions-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Define Functions</a></span></li><li><span><a href=\"#Generate-Data\" data-toc-modified-id=\"Generate-Data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Generate Data</a></span></li></ul></li><li><span><a href=\"#Run-BFGS-on-Koenecker-Data\" data-toc-modified-id=\"Run-BFGS-on-Koenecker-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Run BFGS on Koenecker Data</a></span></li><li><span><a href=\"#Criticize-Results\" data-toc-modified-id=\"Criticize-Results-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Criticize Results</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BFGS to obtain MAP estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T14:59:48.000043Z",
     "start_time": "2018-11-21T14:59:43.592979Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "import edward as ed\n",
    "from edward.models import Beta, Gamma, Exponential\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T14:59:48.078670Z",
     "start_time": "2018-11-21T14:59:48.002206Z"
    }
   },
   "outputs": [],
   "source": [
    "sess = ed.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T14:59:48.111503Z",
     "start_time": "2018-11-21T14:59:48.080395Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('kronecker-core-periphery-n1024-h10-r0_01-0_25-1000-cascades.txt','r') as f:\n",
    "    \n",
    "    # Store number of nodes\n",
    "    numNodes = -1\n",
    "    while True:\n",
    "        if f.readline() == \"\\n\":\n",
    "            break\n",
    "        numNodes+=1\n",
    "\n",
    "    # Collect cascades into list\n",
    "    v = []\n",
    "    for line in f.readlines():\n",
    "        v.append([float(l) for l in line.rstrip('\\n').split(\",\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T14:59:48.147631Z",
     "start_time": "2018-11-21T14:59:48.113492Z"
    }
   },
   "outputs": [],
   "source": [
    "np_cascades = np.ones((len(v),numNodes),np.float32)*10\n",
    "for row, cascade in enumerate(v):  \n",
    "    c_nodes = [int(cascade[i*2]) for i in range(len(cascade)//2)]\n",
    "    c_times = [cascade[i*2+1] for i in range(len(cascade)//2)]\n",
    "\n",
    "    for col in range(len(c_nodes)):\n",
    "        np_cascades[row][c_nodes[col]]=c_times[col]\n",
    "        \n",
    "casc = np_cascades[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T14:59:49.647705Z",
     "start_time": "2018-11-21T14:59:49.642345Z"
    }
   },
   "outputs": [],
   "source": [
    "def cascadeLogProb(time, seed):\n",
    "    np.where()\n",
    "    \n",
    "    \n",
    "    # Store number of nodes\n",
    "    n = time.shape[0]\n",
    "\n",
    "    # Transpose times and reduce minimum\n",
    "    times_T = tf.minimum(tf.transpose(time),T)\n",
    "\n",
    "    # Initialize transmission times to be max time except for seed node\n",
    "    transmission = tf.ones(n)*T\n",
    "    transmission = tf.subtract(transmission,tf.one_hot(seed, n)*T)\n",
    "\n",
    "    \n",
    "    # Continually update transmissions\n",
    "    for _ in range(n):\n",
    "\n",
    "        # Tile transmission\n",
    "        transmission_tiled = tf.reshape(tf.tile(transmission,[n]),[n,n])\n",
    "\n",
    "        # Add transposed times and tiled transmissions\n",
    "        potential_transmission = tf.add(transmission_tiled,times_T)\n",
    "\n",
    "        # Find minimum path from all new \n",
    "        potential_transmission_row = tf.reduce_min(potential_transmission, reduction_indices=[1])\n",
    "\n",
    "        # Concatenate previous transmission and potential new transmission\n",
    "        potential_transmission_stack = tf.stack([transmission,potential_transmission_row],axis=0)\n",
    "\n",
    "        # Take the minimum of the original transmission and the potential new transmission\n",
    "        transmission = tf.reduce_min(potential_transmission_stack, reduction_indices=[0])\n",
    "\n",
    "    return transmission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T14:59:51.774580Z",
     "start_time": "2018-11-21T14:59:51.769030Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_cascade(time, seed, T):\n",
    "    # Store number of nodes\n",
    "    n = time.shape[0]\n",
    "\n",
    "    # Transpose times and reduce minimum\n",
    "    times_T = tf.minimum(tf.transpose(time),T)\n",
    "\n",
    "    # Initialize transmission times to be max time except for seed node\n",
    "    transmission = tf.ones(n)*T\n",
    "    transmission = tf.subtract(transmission,tf.one_hot(seed, n)*T)\n",
    "\n",
    "    \n",
    "    # Continually update transmissions\n",
    "    for _ in range(n):\n",
    "\n",
    "        # Tile transmission\n",
    "        transmission_tiled = tf.reshape(tf.tile(transmission,[n]),[n,n])\n",
    "\n",
    "        # Add transposed times and tiled transmissions\n",
    "        potential_transmission = tf.add(transmission_tiled,times_T)\n",
    "\n",
    "        # Find minimum path from all new \n",
    "        potential_transmission_row = tf.reduce_min(potential_transmission, reduction_indices=[1])\n",
    "\n",
    "        # Concatenate previous transmission and potential new transmission\n",
    "        potential_transmission_stack = tf.stack([transmission,potential_transmission_row],axis=0)\n",
    "\n",
    "        # Take the minimum of the original transmission and the potential new transmission\n",
    "        transmission = tf.reduce_min(potential_transmission_stack, reduction_indices=[0])\n",
    "\n",
    "    return transmission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T14:59:53.928007Z",
     "start_time": "2018-11-21T14:59:53.771430Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha = np.array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "                  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=np.float32)\n",
    "\n",
    "alpha_tf = tf.convert_to_tensor(alpha, dtype=tf.float32)\n",
    "\n",
    "tau = Exponential(alpha)\n",
    "\n",
    "test_cascade = sess.run(build_cascade(tau, 0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T14:59:54.555240Z",
     "start_time": "2018-11-21T14:59:54.552443Z"
    }
   },
   "outputs": [],
   "source": [
    "test_cascade = test_cascade.reshape((1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run BFGS on Koenecker Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:03:21.028919Z",
     "start_time": "2018-11-21T15:03:21.026347Z"
    }
   },
   "outputs": [],
   "source": [
    "numNodes=1023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:03:21.878211Z",
     "start_time": "2018-11-21T15:03:21.873444Z"
    }
   },
   "outputs": [],
   "source": [
    "def infectedCascade(cascade, N=numNodes, T=10):\n",
    "    inf = np.zeros((N,N))\n",
    "    \n",
    "    c_nodes = [int(cascade[i*2]) for i in range(len(cascade)//2)]\n",
    "    c_times = [cascade[i*2+1] for i in range(len(cascade)//2)]\n",
    "\n",
    "\n",
    "    for i in range(len(c_nodes)):\n",
    "        for j in range(i):\n",
    "            if cascade[j] < T:\n",
    "                inf[(c_nodes[i],c_nodes[j])]=c_times[i]-c_times[j]\n",
    "    \n",
    "    return tf.convert_to_tensor(inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:03:22.525680Z",
     "start_time": "2018-11-21T15:03:22.521057Z"
    }
   },
   "outputs": [],
   "source": [
    "def uninfectedCascade(cascade,N=numNodes,T=6):    \n",
    "    nodes = {s for s in range(N)}\n",
    "    uninf = np.zeros((N,N))\n",
    "\n",
    "    c_nodes = [int(cascade[i*2]) for i in range(len(cascade)//2)]\n",
    "    c_times = [cascade[i*2+1] for i in range(len(cascade)//2)]\n",
    "\n",
    "    \n",
    "    for i in range(len(c_nodes)):\n",
    "        for j in (nodes-set(c_nodes)):\n",
    "            uninf[c_nodes[i],j]=T-c_times[i]\n",
    "\n",
    "    return tf.convert_to_tensor(uninf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:03:23.085414Z",
     "start_time": "2018-11-21T15:03:23.081992Z"
    }
   },
   "outputs": [],
   "source": [
    "def genInfectedTensor(v):\n",
    "    tf_infected = None\n",
    "    for cascade in v:\n",
    "        if tf_infected == None:\n",
    "            tf_infected = tf.expand_dims(infectedCascade(cascade),0)\n",
    "        else:\n",
    "            tf_infected = tf.concat([tf_infected,tf.expand_dims(infectedCascade(cascade),0)],axis=0)\n",
    "    return tf_infected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:03:23.859054Z",
     "start_time": "2018-11-21T15:03:23.856022Z"
    }
   },
   "outputs": [],
   "source": [
    "def genUninfectedTensor(v):\n",
    "    tf_uninfected = None\n",
    "    for cascade in v:\n",
    "        if tf_uninfected == None:\n",
    "            tf_uninfected = tf.expand_dims(uninfectedCascade(cascade),0)\n",
    "        else:\n",
    "            tf_uninfected = tf.concat([tf_uninfected,tf.expand_dims(uninfectedCascade(cascade),0)],axis=0)\n",
    "    return tf_uninfected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:03:26.896540Z",
     "start_time": "2018-11-21T15:03:26.633201Z"
    }
   },
   "outputs": [],
   "source": [
    "I = genInfectedTensor(v[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:03:27.663595Z",
     "start_time": "2018-11-21T15:03:27.306065Z"
    }
   },
   "outputs": [],
   "source": [
    "U = genUninfectedTensor(v[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:03:28.032800Z",
     "start_time": "2018-11-21T15:03:28.028147Z"
    }
   },
   "outputs": [],
   "source": [
    "U_ph = tf.placeholder(tf.float32, U.shape)\n",
    "I_ph = tf.placeholder(tf.float32, I.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:03:28.634623Z",
     "start_time": "2018-11-21T15:03:28.624778Z"
    }
   },
   "outputs": [],
   "source": [
    "B = tf.Variable(tf.random_uniform(U.shape[1:]), dtype=tf.float32)\n",
    "alpha_tensor = tf.nn.sigmoid(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:03:32.212399Z",
     "start_time": "2018-11-21T15:03:32.178264Z"
    }
   },
   "outputs": [],
   "source": [
    "def f_psi_1(alpha_tensor, infected):\n",
    "    return -tf.reduce_sum(tf.multiply(alpha_tensor,tf.cast(infected,dtype=tf.float32)))\n",
    "\n",
    "psi_1 = tf.map_fn(lambda x: f_psi_1(alpha_tensor, x), I_ph, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:03:32.777245Z",
     "start_time": "2018-11-21T15:03:32.738227Z"
    }
   },
   "outputs": [],
   "source": [
    "def f_psi_2(alpha_tensor, uninfected):\n",
    "    return -tf.reduce_sum(tf.multiply(tf.transpose(alpha_tensor),tf.cast(uninfected,dtype=tf.float32)))\n",
    "\n",
    "psi_2 = tf.map_fn(lambda x: f_psi_2(alpha_tensor, x), U_ph, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:03:33.223045Z",
     "start_time": "2018-11-21T15:03:33.184290Z"
    }
   },
   "outputs": [],
   "source": [
    "def f_psi_3(alpha_tensor, infected):\n",
    "    infected_sign = tf.cast(tf.sign(infected),tf.float32)\n",
    "    \n",
    "    # Row sum infected\n",
    "    alpha_tensor_row = tf.reduce_sum(tf.multiply(infected_sign,alpha_tensor),axis=1)\n",
    "    \n",
    "    # Add 1 to 0 entries so log(1)=0\n",
    "    alpha_tensor_row_zeros = -tf.cast(tf.sign(alpha_tensor_row),tf.float32)+1\n",
    "    return tf.reduce_sum(tf.log(tf.add(alpha_tensor_row,alpha_tensor_row_zeros)))\n",
    "\n",
    "psi_3 = tf.map_fn(lambda x: f_psi_3(alpha_tensor, x), I_ph, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:03:34.251816Z",
     "start_time": "2018-11-21T15:03:34.249119Z"
    }
   },
   "outputs": [],
   "source": [
    "# alphas_test = tf.ones((numNodes,numNodes))/10\n",
    "\n",
    "# print(\"psi 1: {}\".format(f_psi_1(alphas_test,I.eval()).eval()))\n",
    "# print(\"psi 2: {}\".format(f_psi_2(alphas_test,U.eval()).eval()))\n",
    "# print(\"psi 3: {}\".format(f_psi_3(alphas_test,I.eval()).eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:03:35.953343Z",
     "start_time": "2018-11-21T15:03:35.944790Z"
    }
   },
   "outputs": [],
   "source": [
    "log_p = -(tf.reduce_sum(psi_1)+tf.reduce_sum(psi_2)+tf.reduce_sum(psi_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:00:47.859072Z",
     "start_time": "2018-11-21T15:00:22.016769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: -389559.125000\n",
      "  Number of iterations: 24\n",
      "  Number of functions evaluations: 56\n"
     ]
    }
   ],
   "source": [
    "max_iter = 1000\n",
    "\n",
    "data = {U_ph: U.eval(),\n",
    "        I_ph: I.eval()}\n",
    "\n",
    "optimizer = tf.contrib.opt.ScipyOptimizerInterface(log_p,\n",
    "                                                   method='L-BFGS-B',\n",
    "                                                   options={\n",
    "                                                    'maxiter': max_iter})\n",
    "model = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(model)\n",
    "optimizer.minimize(sess, feed_dict=data)\n",
    "b = B.eval(session=sess)\n",
    "a = alpha_tensor.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criticize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T15:04:23.190953Z",
     "start_time": "2018-11-21T15:04:23.186079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order\t node\t time\n",
      "-----\t ----\t ----\n",
      "    1\t  753\t 0.00\n",
      "    2\t  261\t 1.35\n",
      "    3\t  704\t 3.97\n",
      "    4\t  145\t 4.90\n",
      "    5\t   73\t 5.93\n",
      "    6\t  286\t 6.63\n",
      "    7\t  556\t 7.84\n",
      "    8\t   80\t 8.14\n",
      "    9\t  458\t 8.78\n",
      "   10\t    8\t 8.79\n",
      "   11\t  467\t 8.90\n",
      "   12\t  554\t 8.91\n",
      "   13\t   53\t 9.24\n",
      "   14\t    1\t 9.45\n",
      "   15\t  584\t 9.59\n",
      "   16\t  843\t 9.60\n",
      "   17\t  116\t 9.78\n",
      "   18\t  130\t 9.82\n",
      "   19\t  545\t 9.83\n",
      "   20\t  579\t 9.97\n",
      "   21\t  535\t 9.98\n"
     ]
    }
   ],
   "source": [
    "def printCascade(cascade):\n",
    "    print(\"order\\t node\\t time\")\n",
    "    print(\"-----\\t ----\\t ----\")\n",
    "    for i in range(len(cascade)//2):\n",
    "        print('{:5d}\\t {:4d}\\t {:0.2f}'.format(i+1,int(cascade[i*2]), cascade[i*2+1]))\n",
    "\n",
    "printCascade(v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
