{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Using-BFGS-to-obtain-MAP-estimate\" data-toc-modified-id=\"Using-BFGS-to-obtain-MAP-estimate-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Using BFGS to obtain MAP estimate</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-Functions\" data-toc-modified-id=\"Define-Functions-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Define Functions</a></span></li><li><span><a href=\"#Generate-Data\" data-toc-modified-id=\"Generate-Data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Generate Data</a></span></li></ul></li><li><span><a href=\"#Run-BFGS-on-Koenecker-Data\" data-toc-modified-id=\"Run-BFGS-on-Koenecker-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Run BFGS on Koenecker Data</a></span></li><li><span><a href=\"#Criticize-Results\" data-toc-modified-id=\"Criticize-Results-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Criticize Results</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BFGS to obtain MAP estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T02:56:14.341468Z",
     "start_time": "2018-11-27T02:56:04.674461Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import edward2 as ed\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T02:56:14.348210Z",
     "start_time": "2018-11-27T02:56:14.344185Z"
    }
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T02:56:14.386992Z",
     "start_time": "2018-11-27T02:56:14.350462Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('kronecker-core-periphery-n1024-h10-r0_01-0_25-1000-cascades.txt','r') as f:\n",
    "    \n",
    "    # Store number of nodes\n",
    "    numNodes = -1\n",
    "    while True:\n",
    "        if f.readline() == \"\\n\":\n",
    "            break\n",
    "        numNodes+=1\n",
    "\n",
    "    # Collect cascades into list\n",
    "    v = []\n",
    "    for line in f.readlines():\n",
    "        v.append([float(l) for l in line.rstrip('\\n').split(\",\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T02:56:14.419320Z",
     "start_time": "2018-11-27T02:56:14.389526Z"
    }
   },
   "outputs": [],
   "source": [
    "np_cascades = np.ones((len(v),numNodes),np.float32)*10\n",
    "for row, cascade in enumerate(v):  \n",
    "    c_nodes = [int(cascade[i*2]) for i in range(len(cascade)//2)]\n",
    "    c_times = [cascade[i*2+1] for i in range(len(cascade)//2)]\n",
    "\n",
    "    for col in range(len(c_nodes)):\n",
    "        np_cascades[row][c_nodes[col]]=c_times[col]\n",
    "        \n",
    "casc = np_cascades[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T02:56:14.427665Z",
     "start_time": "2018-11-27T02:56:14.421638Z"
    }
   },
   "outputs": [],
   "source": [
    "def cascadeLogProb(time, seed):\n",
    "    np.where()\n",
    "    \n",
    "    \n",
    "    # Store number of nodes\n",
    "    n = time.shape[0]\n",
    "\n",
    "    # Transpose times and reduce minimum\n",
    "    times_T = tf.minimum(tf.transpose(time),T)\n",
    "\n",
    "    # Initialize transmission times to be max time except for seed node\n",
    "    transmission = tf.ones(n)*T\n",
    "    transmission = tf.subtract(transmission,tf.one_hot(seed, n)*T)\n",
    "\n",
    "    \n",
    "    # Continually update transmissions\n",
    "    for _ in range(n):\n",
    "\n",
    "        # Tile transmission\n",
    "        transmission_tiled = tf.reshape(tf.tile(transmission,[n]),[n,n])\n",
    "\n",
    "        # Add transposed times and tiled transmissions\n",
    "        potential_transmission = tf.add(transmission_tiled,times_T)\n",
    "\n",
    "        # Find minimum path from all new \n",
    "        potential_transmission_row = tf.reduce_min(potential_transmission, reduction_indices=[1])\n",
    "\n",
    "        # Concatenate previous transmission and potential new transmission\n",
    "        potential_transmission_stack = tf.stack([transmission,potential_transmission_row],axis=0)\n",
    "\n",
    "        # Take the minimum of the original transmission and the potential new transmission\n",
    "        transmission = tf.reduce_min(potential_transmission_stack, reduction_indices=[0])\n",
    "\n",
    "    return transmission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T02:56:14.434763Z",
     "start_time": "2018-11-27T02:56:14.429352Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_cascade(time, seed, T):\n",
    "    # Store number of nodes\n",
    "    n = time.shape[0]\n",
    "\n",
    "    # Transpose times and reduce minimum\n",
    "    times_T = tf.minimum(tf.transpose(time),T)\n",
    "\n",
    "    # Initialize transmission times to be max time except for seed node\n",
    "    transmission = tf.ones(n)*T\n",
    "    transmission = tf.subtract(transmission,tf.one_hot(seed, n)*T)\n",
    "\n",
    "    \n",
    "    # Continually update transmissions\n",
    "    for _ in range(n):\n",
    "\n",
    "        # Tile transmission\n",
    "        transmission_tiled = tf.reshape(tf.tile(transmission,[n]),[n,n])\n",
    "\n",
    "        # Add transposed times and tiled transmissions\n",
    "        potential_transmission = tf.add(transmission_tiled,times_T)\n",
    "\n",
    "        # Find minimum path from all new \n",
    "        potential_transmission_row = tf.reduce_min(potential_transmission, reduction_indices=[1])\n",
    "\n",
    "        # Concatenate previous transmission and potential new transmission\n",
    "        potential_transmission_stack = tf.stack([transmission,potential_transmission_row],axis=0)\n",
    "\n",
    "        # Take the minimum of the original transmission and the potential new transmission\n",
    "        transmission = tf.reduce_min(potential_transmission_stack, reduction_indices=[0])\n",
    "\n",
    "    return transmission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T02:56:14.448231Z",
     "start_time": "2018-11-27T02:56:14.436504Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha_0 = np.array([[0, 1, 0, 0, .5, 0, 0, 0, 0, 0],\n",
    "                    [0, 0, 1, .3, 0, 0, 2, .5, 0, 0],\n",
    "                    [0, 0, 0, 1, 0, 0, 0, .2, 0, 0],\n",
    "                    [0, 0, 0, 0, 1, 0, .1, 0, .5, 0],\n",
    "                    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 1, 0, .2, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=np.float32)\n",
    "\n",
    "alpha_1 = np.array([[0, 1, 0, .3, .8, 0, 0, 1.2, 0, 0],\n",
    "                    [0, 0, 1.4, .3, 0, 0, 3.5, .6, 0, 0],\n",
    "                    [0, 0, 0, .5, 0, 0, 0, .3, 0, 0],\n",
    "                    [0, 0, 0, 0, .5, 0, .7, 0, .4, 0],\n",
    "                    [0, 0, 0, 0, 0, .8, 0, 0, 1.5, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 1.4, 0, .6, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 1.1, 0, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 0, 1.7, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 0, 0, .2],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=np.float32)\n",
    "\n",
    "alpha = np.stack((alpha_0,alpha_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:00:34.881385Z",
     "start_time": "2018-11-27T03:00:34.873489Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def sampleCascade(alpha, T, n):\n",
    "    alpha_tf = tf.convert_to_tensor(alpha, dtype=tf.float32)\n",
    "    nodes = alpha.shape[1]\n",
    "    \n",
    "    np_topics = np.zeros((n,2))\n",
    "    \n",
    "    \n",
    "    cascade=[]\n",
    "    topic=[]\n",
    "    for i in tqdm_notebook(range(n)):\n",
    "        topic_pos = random.randint(0,1)\n",
    "        np_topics[i,topic_pos]=1\n",
    "        \n",
    "        tau = ed.Exponential(tf.gather(alpha_tf,indices=topic_pos))\n",
    "        seed = random.randint(0,nodes-1)\n",
    "        \n",
    "        tmpCascade = sess.run(build_cascade(tau, seed, T))\n",
    "        \n",
    "        \n",
    "        order = tmpCascade.argsort()\n",
    "        times = tmpCascade[order]\n",
    "        \n",
    "        cascadeList=[]\n",
    "        \n",
    "        for i in range(nodes):\n",
    "            if times[i]>=T: break\n",
    "            cascadeList.append(float(order[i]))\n",
    "            cascadeList.append(times[i])\n",
    "\n",
    "        cascade.append(cascadeList)\n",
    "        \n",
    "    return np_topics, cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:06:56.525372Z",
     "start_time": "2018-11-27T03:06:56.520867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_topics, test_cascade = sampleCascade(alpha,10,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run BFGS on Koenecker Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:04:32.356016Z",
     "start_time": "2018-11-27T03:04:32.352449Z"
    }
   },
   "outputs": [],
   "source": [
    "numNodes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:04:32.965278Z",
     "start_time": "2018-11-27T03:04:32.959547Z"
    }
   },
   "outputs": [],
   "source": [
    "def infectedCascade(cascade, N=numNodes, T=10):\n",
    "    inf = np.zeros((N,N))\n",
    "    \n",
    "    c_nodes = [int(cascade[i*2]) for i in range(len(cascade)//2)]\n",
    "    c_times = [cascade[i*2+1] for i in range(len(cascade)//2)]\n",
    "\n",
    "\n",
    "    for i in range(len(c_nodes)):\n",
    "        for j in range(i):\n",
    "            if cascade[j] < T:\n",
    "                inf[(c_nodes[i],c_nodes[j])]=c_times[i]-c_times[j]\n",
    "    \n",
    "    return tf.convert_to_tensor(inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:04:33.258128Z",
     "start_time": "2018-11-27T03:04:33.250231Z"
    }
   },
   "outputs": [],
   "source": [
    "def uninfectedCascade(cascade,N=numNodes,T=10):\n",
    "    nodes = {s for s in range(N)}\n",
    "    uninf = np.zeros((N,N))\n",
    "\n",
    "    c_nodes = [int(cascade[i*2]) for i in range(len(cascade)//2)]\n",
    "    c_times = [cascade[i*2+1] for i in range(len(cascade)//2)]\n",
    "\n",
    "    \n",
    "    for i in range(len(c_nodes)):\n",
    "        for j in (nodes-set(c_nodes)):\n",
    "            uninf[c_nodes[i],j]=T-c_times[i]\n",
    "\n",
    "    return tf.convert_to_tensor(uninf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:04:33.637856Z",
     "start_time": "2018-11-27T03:04:33.633250Z"
    }
   },
   "outputs": [],
   "source": [
    "def genInfectedTensor(v):\n",
    "    tf_infected = None\n",
    "    for cascade in v:\n",
    "        if tf_infected == None:\n",
    "            tf_infected = tf.expand_dims(infectedCascade(cascade),0)\n",
    "        else:\n",
    "            tf_infected = tf.concat([tf_infected,tf.expand_dims(infectedCascade(cascade),0)],axis=0)\n",
    "    return tf_infected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:04:34.043391Z",
     "start_time": "2018-11-27T03:04:34.038232Z"
    }
   },
   "outputs": [],
   "source": [
    "def genUninfectedTensor(v):\n",
    "    tf_uninfected = None\n",
    "    for cascade in v:\n",
    "        if tf_uninfected == None:\n",
    "            tf_uninfected = tf.expand_dims(uninfectedCascade(cascade),0)\n",
    "        else:\n",
    "            tf_uninfected = tf.concat([tf_uninfected,tf.expand_dims(uninfectedCascade(cascade),0)],axis=0)\n",
    "    return tf_uninfected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:04:35.515937Z",
     "start_time": "2018-11-27T03:04:34.959926Z"
    }
   },
   "outputs": [],
   "source": [
    "I = genInfectedTensor(test_cascade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:04:36.225803Z",
     "start_time": "2018-11-27T03:04:35.617730Z"
    }
   },
   "outputs": [],
   "source": [
    "U = genUninfectedTensor(test_cascade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:04:36.622194Z",
     "start_time": "2018-11-27T03:04:36.617789Z"
    }
   },
   "outputs": [],
   "source": [
    "topics = tf.convert_to_tensor(test_topics,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:04:37.269051Z",
     "start_time": "2018-11-27T03:04:37.263043Z"
    }
   },
   "outputs": [],
   "source": [
    "U_ph = tf.placeholder(tf.float32, U.shape)\n",
    "I_ph = tf.placeholder(tf.float32, I.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:07:35.391343Z",
     "start_time": "2018-11-27T03:07:34.079981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5],\n",
       "       [0.5]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numTopics = 2\n",
    "theta_topics = tf.reshape(tf.divide(tf.ones((1,numTopics)),numTopics),(numTopics,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:04:38.477984Z",
     "start_time": "2018-11-27T03:04:38.462712Z"
    }
   },
   "outputs": [],
   "source": [
    "rate_intercept = tf.get_variable('rate_intercept', initializer=tf.zeros_initializer, shape=(10,10))\n",
    "rate_affinity = tf.get_variable('rate_affinity', initializer=tf.zeros_initializer, shape=(10,10,numTopics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:10:49.970435Z",
     "start_time": "2018-11-27T03:10:49.896819Z"
    }
   },
   "outputs": [],
   "source": [
    "def f_psi_1(rate_intercept, rate_affinity, infected, topic):\n",
    "    rate_affinity_rshp = tf.add(tf.reshape(rate_affinity,(100,2)),.001)\n",
    "    topic_rshp = tf.reshape(topic,(2,1))\n",
    "    affinity = tf.reshape(tf.matmul(rate_affinity_rshp,topic_rshp),(10,10))\n",
    "    \n",
    "    alpha_tensor = tf.add(tf.nn.relu(tf.add(rate_intercept,affinity)),.001)\n",
    "    return -tf.reduce_sum(tf.multiply(alpha_tensor,tf.cast(infected,dtype=tf.float32)))\n",
    "\n",
    "psi_1 = tf.map_fn(lambda x: f_psi_1(rate_intercept, rate_affinity, x[0], x[1]), (I_ph, topics), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:10:50.817112Z",
     "start_time": "2018-11-27T03:10:50.729384Z"
    }
   },
   "outputs": [],
   "source": [
    "def f_psi_2(rate_intercept, rate_affinity, uninfected, topic):\n",
    "    rate_affinity_rshp = tf.add(tf.reshape(rate_affinity,(100,2)),.001)\n",
    "    topic_rshp = tf.reshape(topic,(2,1))\n",
    "    affinity = tf.reshape(tf.matmul(rate_affinity_rshp,topic_rshp),(10,10))\n",
    "    \n",
    "    alpha_tensor = tf.add(tf.nn.relu(tf.add(rate_intercept,affinity)),.001)\n",
    "    \n",
    "    return -tf.reduce_sum(tf.multiply(tf.transpose(alpha_tensor),tf.cast(uninfected,dtype=tf.float32)))\n",
    "\n",
    "psi_2 = tf.map_fn(lambda x: f_psi_2(rate_intercept, rate_affinity, x[0], x[1]), (U_ph, topics), dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:10:51.413581Z",
     "start_time": "2018-11-27T03:10:51.317212Z"
    }
   },
   "outputs": [],
   "source": [
    "def f_psi_3(rate_intercept, rate_affinity, infected, topic):\n",
    "    rate_affinity_rshp = tf.add(tf.reshape(rate_affinity,(100,2)),.001)\n",
    "    topic_rshp = tf.reshape(topic,(2,1))\n",
    "    alpha_tensor = tf.add(tf.nn.relu(tf.add(rate_intercept,tf.reshape(tf.matmul(rate_affinity_rshp,topic_rshp),(10,10)))),.001)\n",
    "    \n",
    "    infected_sign = tf.cast(tf.sign(infected),tf.float32)\n",
    "    \n",
    "    # Row sum infected\n",
    "    alpha_tensor_row = tf.reduce_sum(tf.multiply(infected_sign,alpha_tensor),axis=1)\n",
    "    \n",
    "    # Add 1 to 0 entries so log(1)=0\n",
    "    alpha_tensor_row_zeros = -tf.cast(tf.sign(alpha_tensor_row),tf.float32)+1\n",
    "    \n",
    "    return tf.reduce_sum(tf.log(tf.add(alpha_tensor_row,alpha_tensor_row_zeros)))\n",
    "\n",
    "psi_3 = tf.map_fn(lambda x: f_psi_3(rate_intercept, rate_affinity, x[0], x[1]), (I_ph, topics), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:19:24.668521Z",
     "start_time": "2018-11-27T03:19:24.655762Z"
    }
   },
   "outputs": [],
   "source": [
    "def gamma_prior(rate_intercept, rate_affinity, theta_topics):\n",
    "    rate_affinity_rshp = tf.add(tf.reshape(rate_affinity,(100,2)),.001)\n",
    "    \n",
    "    return -tf.add(tf.nn.relu(rate_intercept+tf.reshape(tf.matmul(rate_affinity_rshp,theta_topics),(10,10))),.001)\n",
    "\n",
    "prior = gamma_prior(rate_intercept, rate_affinity,theta_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:19:25.158310Z",
     "start_time": "2018-11-27T03:19:25.145534Z"
    }
   },
   "outputs": [],
   "source": [
    "log_p = -(tf.reduce_sum(prior) + tf.reduce_sum(psi_1)+tf.reduce_sum(psi_2)+tf.reduce_sum(psi_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:19:33.551454Z",
     "start_time": "2018-11-27T03:19:25.657287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 1022.493530\n",
      "  Number of iterations: 27\n",
      "  Number of functions evaluations: 74\n"
     ]
    }
   ],
   "source": [
    "max_iter = 2000\n",
    "\n",
    "data = {U_ph: U.eval(session=sess),\n",
    "        I_ph: I.eval(session=sess)}\n",
    "\n",
    "optimizer = tf.contrib.opt.ScipyOptimizerInterface(log_p, \n",
    "                                                   method='L-BFGS-B',\n",
    "                                                   options={'maxiter': max_iter})\n",
    "model = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(model)\n",
    "optimizer.minimize(sess, feed_dict=data)\n",
    "# a = alpha_tensor.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:19:33.561609Z",
     "start_time": "2018-11-27T03:19:33.554100Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluateAlpha(rate_intercept, rate_affinity, topic):\n",
    "    rate_affinity_rshp = tf.add(tf.reshape(rate_affinity,(100,2)),.001)\n",
    "    topic_rshp = tf.convert_to_tensor(np.reshape(topic,(2,1)),dtype=tf.float32)\n",
    "    alpha_tensor = tf.add(tf.nn.relu(tf.add(rate_intercept,tf.reshape(tf.matmul(rate_affinity_rshp,topic_rshp),(10,10)))),.001)\n",
    "    \n",
    "    negative_I = 1-tf.eye(10)\n",
    "    \n",
    "    return tf.multiply(alpha_tensor,negative_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:19:36.281318Z",
     "start_time": "2018-11-27T03:19:33.564362Z"
    }
   },
   "outputs": [],
   "source": [
    "infer_alpha_0 = evaluateAlpha(rate_intercept,rate_affinity,np.array([1,0])).eval(session=sess).transpose().round(1)\n",
    "infer_alpha_1 = evaluateAlpha(rate_intercept,rate_affinity,np.array([0,1])).eval(session=sess).transpose().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:19:36.292052Z",
     "start_time": "2018-11-27T03:19:36.284939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.9, 0. , 0. , 0.7, 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 1.2, 0.2, 0. , 0. , 1.7, 0.3, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 1. , 0. , 0. , 0. , 0.2, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 1. , 0. , 0.1, 0. , 0.3, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 1.1, 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 1.1, 0. , 0.2, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 1.1, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1.1, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_alpha_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:19:36.312848Z",
     "start_time": "2018-11-27T03:19:36.297612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 1. , 0. , 0. , 0.5, 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 1. , 0.3, 0. , 0. , 2. , 0.5, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 1. , 0. , 0. , 0. , 0.2, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 1. , 0. , 0.1, 0. , 0.5, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 1. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 1. , 0. , 0.2, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_0.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:19:36.323373Z",
     "start_time": "2018-11-27T03:19:36.316310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.7, 0. , 0. , 0.7, 0. , 0. , 0.2, 0. , 0. ],\n",
       "       [0. , 0. , 1.3, 0.2, 0. , 0. , 1.7, 0.2, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0.8, 0. , 0. , 0. , 0.6, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0.5, 0. , 0.6, 0. , 0.4, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0.6, 0. , 0. , 1. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 1.4, 0. , 0.6, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 1.4, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1.8, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.2],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_alpha_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:19:36.334816Z",
     "start_time": "2018-11-27T03:19:36.325916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 1. , 0. , 0.3, 0.8, 0. , 0. , 1.2, 0. , 0. ],\n",
       "       [0. , 0. , 1.4, 0.3, 0. , 0. , 3.5, 0.6, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0.5, 0. , 0. , 0. , 0.3, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0.5, 0. , 0.7, 0. , 0.4, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0.8, 0. , 0. , 1.5, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 1.4, 0. , 0.6, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 1.1, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1.7, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.2],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_1.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criticize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T16:17:53.264109Z",
     "start_time": "2018-11-25T16:17:53.258723Z"
    }
   },
   "outputs": [],
   "source": [
    "def printCascade(cascade):\n",
    "    print(\"order\\t node\\t time\")\n",
    "    print(\"-----\\t ----\\t ----\")\n",
    "    for i in range(len(cascade)//2):\n",
    "        print('{:5d}\\t {:4d}\\t {:0.2f}'.format(i+1,int(cascade[i*2]), cascade[i*2+1]))\n",
    "\n",
    "printCascade(v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T16:23:44.236851Z",
     "start_time": "2018-11-25T16:23:44.234297Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T21:30:53.667894Z",
     "start_time": "2018-11-23T21:30:49.476Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer._var_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T21:30:53.668966Z",
     "start_time": "2018-11-23T21:30:49.478Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha = sess.run(optimizer._vars)[0]\n",
    "beta = sess.run(optimizer._vars)[1]\n",
    "tf.nn.relu(beta[753][261])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-23T21:30:53.669663Z",
     "start_time": "2018-11-23T21:30:49.480Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import tensorflow_probability\n",
    "# \n",
    "# .Beta(alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
