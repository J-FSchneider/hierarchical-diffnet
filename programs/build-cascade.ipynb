{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T19:50:32.152896Z",
     "start_time": "2018-11-06T19:50:27.919459Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "import edward as ed\n",
    "from edward.models import Beta\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T19:50:32.158644Z",
     "start_time": "2018-11-06T19:50:32.155129Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.SparseTensor(indices, coo.data, coo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T19:50:32.204955Z",
     "start_time": "2018-11-06T19:50:32.160873Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('kronecker-core-periphery-n1024-h10-r0_01-0_25-1000-cascades.txt','r') as f:\n",
    "    \n",
    "    # Store number of nodes\n",
    "    numNodes = 0\n",
    "    while True:\n",
    "        if f.readline() == \"\\n\":\n",
    "            break\n",
    "        numNodes+=1\n",
    "\n",
    "    # Collect cascades into list\n",
    "    v = []\n",
    "    for line in f.readlines():\n",
    "        v.append([float(l) for l in line.rstrip('\\n').split(\",\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T19:50:36.018631Z",
     "start_time": "2018-11-06T19:50:36.014688Z"
    }
   },
   "outputs": [],
   "source": [
    "def infectedCascade(cascade,N=numNodes):\n",
    "    A_inf = lil_matrix((N-1,N-1))\n",
    "    \n",
    "    c_nodes = [int(cascade[i*2]) for i in range(len(cascade)//2)]\n",
    "    c_times = [cascade[i*2+1] for i in range(len(cascade)//2)]\n",
    "\n",
    "    for i in range(len(c_nodes)):\n",
    "        for j in range(i):\n",
    "            if c_times[j] < T:\n",
    "                A_inf[(c_nodes[i],c_nodes[j])]=c_times[i]-c_times[j]\n",
    "    \n",
    "    return A_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T19:50:37.488970Z",
     "start_time": "2018-11-06T19:50:37.485109Z"
    }
   },
   "outputs": [],
   "source": [
    "def uninfectedCascade(cascade,N=numNodes):\n",
    "    nodes = {s for s in range(N-1)}\n",
    "    A_uninf = lil_matrix((N-1,N-1))\n",
    "    \n",
    "    c_nodes = [int(cascade[i*2]) for i in range(len(cascade)//2)]\n",
    "    c_times = [cascade[i*2+1] for i in range(len(cascade)//2)]\n",
    "\n",
    "    for i in range(len(c_nodes)):\n",
    "        for j in (nodes-set(c_nodes)):\n",
    "            A_uninf[c_nodes[i],j]=T-c_times[i]\n",
    "    \n",
    "    return A_uninf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T19:50:37.986477Z",
     "start_time": "2018-11-06T19:50:37.901248Z"
    }
   },
   "outputs": [],
   "source": [
    "T=10\n",
    "I = infectedCascade(v[0])\n",
    "U = uninfectedCascade(v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T16:25:56.249297Z",
     "start_time": "2018-11-05T16:25:56.196709Z"
    }
   },
   "outputs": [],
   "source": [
    "I_ph = tf.placeholder(tf.float32, [numNodes-1,numNodes-1])\n",
    "U_ph = tf.placeholder(tf.float32, [numNodes-1,numNodes-1])\n",
    "likelihood_ph = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "A = Beta(tf.ones([numNodes-1,numNodes-1]),tf.ones([numNodes-1,numNodes-1]))\n",
    "\n",
    "psi_1 = -tf.reduce_sum(tf.multiply(A,I_ph))\n",
    "psi_2 = -tf.reduce_sum(tf.multiply(tf.transpose(A),U_ph))\n",
    "psi_3 = tf.reduce_sum(tf.multiply(tf.transpose(A),tf.sign(I_ph)))\n",
    "\n",
    "log_prob = psi_1+psi_2+psi_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T16:25:56.679080Z",
     "start_time": "2018-11-05T16:25:56.676700Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    I_ph: I,\n",
    "    U_ph: U}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T15:18:11.376637Z",
     "start_time": "2018-10-31T15:18:11.311991Z"
    }
   },
   "outputs": [],
   "source": [
    "inference = ed.MAP([A], data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-31T15:18:15.642814Z",
     "start_time": "2018-10-31T15:18:15.168183Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-271-f36b6fd22dd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/src/edward/edward/inferences/inference.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, variables, use_coordinator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_coordinator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   2283\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m     \"\"\"\n\u001b[0;32m-> 2285\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2287\u001b[0m \u001b[0m_gradient_registry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegistry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   4934\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4935\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 4936\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "sess = ed.get_session()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "inference.run(n_iter=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T19:59:23.387668Z",
     "start_time": "2018-11-05T19:59:23.324561Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from edward.models.random_variable import RandomVariable\n",
    "from tensorflow.contrib.distributions import Distribution\n",
    "\n",
    "try:\n",
    "    from tensorflow.contrib.distributions import FULLY_REPARAMETERIZED\n",
    "except Exception as e:\n",
    "    raise ImportError(\"{0}. Your TensorFlow version is not supported.\".format(e))\n",
    "\n",
    "class Cascade(RandomVariable, Distribution):\n",
    "    def __init__(self,\n",
    "                params,\n",
    "                validate_args=False,\n",
    "                allow_nan_stats=True,\n",
    "                name=\"Cascade\"):\n",
    "        \"\"\"Initialize an `Cascade` random variable.\n",
    "        Args:\n",
    "            params: tf.Tensor.\n",
    "            Collection of samples. Its outer (left-most) dimension\n",
    "            determines the number of samples.\n",
    "        \"\"\"\n",
    "        parameters = locals()\n",
    "        with tf.name_scope(name, values=[params]):\n",
    "            with tf.control_dependencies([]):\n",
    "                self._params = tf.identity(params, name=\"params\")\n",
    "                try:\n",
    "                    self._n = tf.shape(self._params)[0]\n",
    "                except ValueError:  # scalar params\n",
    "                    self._n = tf.constant(1)\n",
    "                    \n",
    "    super(Cascade, self).__init__(\n",
    "        dtype=self._params.dtype,\n",
    "        reparameterization_type=FULLY_REPARAMETERIZED,\n",
    "        validate_args=validate_args,\n",
    "        allow_nan_stats=allow_nan_stats,\n",
    "        parameters=parameters,\n",
    "        graph_parents=[self._params, self._n],\n",
    "        name=name)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _param_shapes(sample_shape):\n",
    "        return {\"params\": tf.convert_to_tensor(sample_shape, dtype=tf.int32)}\n",
    "\n",
    "    @property\n",
    "    def params(self):\n",
    "        \"\"\"Distribution parameter.\"\"\"\n",
    "        return self._params\n",
    "\n",
    "    @property\n",
    "    def n(self):\n",
    "        \"\"\"Number of samples.\"\"\"\n",
    "        return self._n\n",
    "    \n",
    "    def _log_prob(self, value):\n",
    "        # TODO\n",
    "        # https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distributions/python/ops/distribution.py#L183\n",
    "        raise NotImplementedError(\"log_prob is not implemented\")\n",
    "\n",
    "    def _sample_n(self, n, seed=None):\n",
    "        input_tensor = self.params\n",
    "        if len(input_tensor.shape) == 0:\n",
    "            input_tensor = tf.expand_dims(input_tensor, 0)\n",
    "            multiples = tf.concat([tf.expand_dims(n, 0), [1] * len(self.event_shape)], 0)\n",
    "            return tf.tile(input_tensor, multiples)\n",
    "        else:\n",
    "            probs = tf.ones([self.n]) / tf.cast(self.n, dtype=tf.float32)\n",
    "            cat = tf.contrib.distributions.Categorical(probs)\n",
    "            indices = cat._sample_n(n, seed)\n",
    "            tensor = tf.gather(input_tensor, indices)\n",
    "            return tensor\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T19:50:54.442766Z",
     "start_time": "2018-11-06T19:50:54.438458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([753.      ,   0.      , 261.      ,   1.35072 , 704.      ,\n",
       "         3.966973, 145.      ,   4.897442,  73.      ,   5.925426,\n",
       "       286.      ,   6.630252, 556.      ,   7.843829,  80.      ,\n",
       "         8.141659, 458.      ,   8.775306,   8.      ,   8.788488,\n",
       "       467.      ,   8.902549, 554.      ,   8.908081,  53.      ,\n",
       "         9.237536,   1.      ,   9.451033, 584.      ,   9.591078,\n",
       "       843.      ,   9.602514, 116.      ,   9.780086, 130.      ,\n",
       "         9.81525 , 545.      ,   9.828353, 579.      ,   9.970419,\n",
       "       535.      ,   9.984903])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
